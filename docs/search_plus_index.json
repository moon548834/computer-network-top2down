{"./":{"url":"./","title":"Introduction","keywords":"","body":"一些关于《计算机网络自顶向下》第七版的笔记 const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'computer-network-top2down', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitalk.render('gitalk-container') require(['gitbook'], function(gitbook) { const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'cyc10-rcore-tutorial', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitbook.events.bind('page.change', initMygitalk) function initMygitalk() { gitalk.render('gitalk-container') } }) "},"Chap1.html":{"url":"Chap1.html","title":"第一章：计算机网络","keywords":"","body":"计算机网络 自顶向下方法(原书第6版) 第一章 1.3 packet switching(分组交换) and circuit switching(电路交换) 特点： 电路交换：在通话的全部时间内，通话的两个用户始终占用端到端的通信资源，此时线路的传输效率很低。 分组交换：不需要建立整个连接，以packet为单位灵活发送，对通信链路是逐段占用。 1.4 延时，损失，吞吐量 延时由四部分组成，processing, queuing, transmission, propagation组成，一般而言，processing的延时比较少，可以忽略不计。 processing 里面主要是确定某个host的请求格式是否有效，然后根据地址确定发送给哪个接下来的router。 queuing 是由于router可能先前的请求还没有结束，这个时间取决于线路的繁忙程度 transmission 这个时间定义为 L/R 其中L代表这个包的长度，R代表传输速率，比如R = 100Mbps之类的 propagation 这个延时定义为 d/s 其中d代表distance， s代表speed， 一般而言s比光速慢一点 对于queuing delay,需要注意的是，La/R 指数增加。 就损失而言，因为一个router不可能有无限大的queue，所以当host向一个已经满的router发送一个包的时候，这个包就被丢弃掉了，所以当我们考虑一个节点性能的时候，不仅要考虑delay，还要考虑loss的情况。 对于吞吐量而言，一般router之间的速率很快，所以速度只取决于server到第一个router和，最后的router到client的速率最小值。对于更现实的多个client连接多个server而言，如果R远大于Rs和Rc的话，依然公式不变，如果R比较小的话，那就是R/N了。(图中N是10) 1.5 协议层 +---Protocol---+ | Application | | Transport | | Network | | (Link) | | Physical | +--------------+ 应用层：如HTTP，FTP等 数据单元称为报文(message)。 传输层：TCP，UDP, 负责向两台主机中进程之间的通信提供通用的数据传输服务。 网络层：在TCP/IP体系中，网络层使用IP协议 数据链路层：帧格式 物理层：比特，确定插头电缆连接等。 相比于OSI七层协议，缺少了 presentation layer 和 session layer，前者包括数据压缩描述等，后者包括数据交换的同步与界定。 一个非常直观的描述图，描述PC，交换机，路由器各自工作的layer。 1.6 当网络受到攻击 途径: malware, DoS攻击，DDoS攻击，packet sniffer, ip欺骗， DoS攻击：Vulnerability attack, Bandwidth flooding, connection flooding。 DDoS：分布式的Dos,多个源。 const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'computer-network-top2down', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitalk.render('gitalk-container') require(['gitbook'], function(gitbook) { const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'cyc10-rcore-tutorial', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitbook.events.bind('page.change', initMygitalk) function initMygitalk() { gitalk.render('gitalk-container') } }) "},"Chap2.html":{"url":"Chap2.html","title":"第二章：应用层","keywords":"","body":"第二章 NOTE:从这章开始，使用第七版 2.1 应用层原则 client: 开始通信的进程 socket: 一个接口，可以看成应用和网络的接口API 为了表明接收信息的进程，我们需要规定两种信息，1.host端的地址，2.一个标识符用来表征哪一个接收端的进程 host地址就是一个独特的IP地址，另外的信息是通过端口来提供的，一些应用分配给了特殊的端口，比如网页服务是80，邮件服务是25。 网络提供不止一种的传输层的协议，我们可以通过以下四种维度界定这些协议:可信传输，吞吐量，时延，安全性。 如果这个协议可以确保数据准确传输，那么就是可信的。一些音视频应用程序(如Skype)就不需要这个保证。 对于吞吐量而言，有些应用需要确保速率不变，这称之为带宽敏感。 TCP/IP网络提供了两种传输层的协议：TCP,UDP。 TCP：提供可信传输，在传输信息前进行握手，并且拥有处理阻塞的机制，当出现阻塞时，就减少(遏制)那个传输的进程。TCP没有提供加密的机制，不过一种叫SSL(Secure Sockets Layer)的东西可以实现这个功能，SSL并不是一个和TCP，UDP具有同等地位的传输协议，他只是TCP的加强版。如果一个应用想使用SSL的服务，那么在客户端和服务器端都需要假如相应的代码。 UDP：轻量级的传输协议，没有握手，不提供阻塞抑制，也没有加密措施。 对于时延和吞吐量，其实这两种协议都没有办法保证,(好吧，个人感觉和底层的layer有关) 应用层的协议一般定义了如下内容: 报文的种类 报文的语法，划定的位(?没太懂，反正这几部分差不多就是构成报文的格式) 报文的语义，哪些位代表哪些意思 进程发送和响应报文的规则 2.2 Web和TTTP HTTP(HyperText Transfer Protocol),是Web应用层的协议，一个网页由多个对象构成，一个对象可能是一个简单的文件如HTML页面，一个图片。大多数页面包含一个基本的HTML文件和多个引用的对象。比如一个网页由HTML和5张JPEG图片构成，那么它就有6个对象。 基本的HTML通过其他对象的URL来引用他们，URL由两部分组成 hostname 和 pathname，举例来说 http://www.someSchool.edu/someDepartment/picture.gif www.someSchool.edu是hostname，而/someDepartment/picture.gif/则是pathname。 HTTP使用TCP作为传输层的协议，HTTP客户端首先初始化和server端的连接，这通过socket接口实现，类似的，server端也通过socket接口来发送响应的报文。 HTTP是一个无状态保存的协议，因为HTTP的server端并不保存任何客户端的信息。 在HTTP/1.0里面，请求一个文件就需要初始化关闭TCP连接，这使得每次请求都需要2个RTT加上一个发送时间 这种非连续连接会使得服务器负担很重，所以在HTTP/1.1中改进出了连续连接的方式，它可以让连接在返回响应后仍保持一定的时间，默认的连续连接模式是流水的，这就可以使得客户端连续发送报文请求，每次的间隔只有1个RTT，并且server端一直处于有事做的状态。 HTTP报文 HTTP报文的格式的一个例子： GET /somedir/page.html HTTP/1.1 Host: www.someschool.edu Connection: close User-agent: Mozilla/5.0 Accept-language: fr HTTP的第一行是request line,剩下的行叫作header lines,request line 包含三部分:method, URL, version。 method除了最常用的GET外还有POST，HEAD，PUT和DELETE 下面是一个通用的报文格式 因为上个例子里面，method是GET，所以body是空的，而对于POST而言，POST一般使用在用户填写一些信息的时候，body就不是空的了。 a request generated with a form does not necessarily use the POST method. Instead, HTML forms often use the GET method and include the inputted data (in the form fields) in the requested URL. 实际上一般用POST的也比较少；使用GET方法中的数据位表示也可。 对于其他方法而言 PUT: 代表存储上传一个对象到URL中, HEAD和DELTE顾名思义。 对于server端回复的报文，十分类似 HTTP/1.1 200 OK Connection: close Date: Tue, 18 Aug 2015 15:44:04 GMT Server: Apache/2.2.3 (CentOS) Last-Modified: Tue, 18 Aug 2015 15:11:03 GMT Content-Length: 6821 Content-Type: text/html (data data data data data ...) 只不过是把request line变成了status line,下面是一些常见的状态码: status code meaning 200 OK 301 moved Permanently 400 bad request 404 not found 505 version not support 在谢希仁的书中提到，4xx表示客户的差错，5xx则表示服务器的问题。 Cookies 下面讨论Cookies，虽然HTTP是一个不保留状态的协议，但是对于server端而言，有时候保留客户端的信息也是一件需求，通过Cookies网站就可以追踪用户的信息了 一般而言，Cookies由四部分构成 HTTP响应时候的header line(Set Cookie: xxx) HTTP请求时候的header line(Cookie: xxx) 用户系统的Cookies文件 网站保存Cokkies的数据库 这样Amazon就可以知道给我推荐什么东西了，而且我买东西的时候只需傻瓜一件点击即可，登录的操作也免除了。 这也带来了关于隐私的讨论，我也很赞同隐私在这中间受到了一定的损害。 Web cache Web cache或者说proxy server,代理服务器是拥有自己的硬盘空间来保存最近的请求对象数据，这样用户并不直接去访问server端，而是先看看web cache里面有没有，如果没有web cache就去访问server。 通常Web cache是ISP购买安装的，一般学校里面也会有，这样会大大降低网络的拥堵程度，减少请求的时间。 conditional GET 就像内存和cache的关系一样，有更新的问题，这里才用的方法是发送GET的同时，包含这样一个header line:If-Modified-Since(由web cache发送给最终的服务器端),如果修改了就更新即可。 2.3电子邮件 在不同的邮件server端通过SMTP协议传输，SMTP依托TCP 由上图，一个网络的邮件系统由三部分组成，用户代理(如Outlook)，邮件服务器，SMTP传输协议。 SMTP通信握手信号可读性很好。这是一个例子： S: 220 hamburger.edu C: HELO crepes.fr S: 250 Hello crepes.fr, pleased to meet youC: MAIL FROM: C: MAIL FROM: S: 250 alice@crepes.fr ... Sender ok C: RCPT TO: S: 250 bob@hamburger.edu ... Recipient ok C: DATA S: 354 Enter mail, end with ”.” on a line by itself C: Do you like ketchup? C: How about pickles? C: . S: 250 Message accepted for delivery C: QUIT S: 221 hamburger.edu closing connection Client端使用了五个命令,HELO,FROM,RCPT TO,DATA,QUIT，都不需要额外解释。 另外SMTP还是一个持续连接，这意味着A mail server发送给B mail server很多邮件时，可以在1个TCP中发送全部数据。 SMTP和HTTP对比 SMTP HTTP 必须是7-bit ASCII 无要求 方向是 push 方向是pull 多object一message 一object一message SMTP要求邮件主体必须是7-bit的ASCII码， header格式 From: alice@crepes.fr To: bob@hamburger.edu Subject: XXX 用户在PC上运行用户代理，理论上讲，邮件server可以在他的PC上，单这要求他的PC一直不关机，所以通常的办法如上图所示。需要注意的是，SMTP是一个push的协议，所以对于图中Bob的server端到Bob的用户代理，不能用SMTP。这部分通常用POP3，IMAP或者HTTP完成。 POP3是一个非常简单的协议，用户代理只有4个命令list,retr(获取),dele,quit。一个例子： C: list S: 1 498 S: 2 912S: . S: . C: retr 1 S: (blah blah ... S: ................. S: ..........blah) S: . C: dele 1 C: retr 2 S: (blah blah ... S: ................. S: ..........blah) S: . C: dele 2 C: quit S: +OK POP3 server signing off . 用来结束文件 POP3协议的一个特点是，只要用户从POP3服务器读取了邮件，这个邮件就会被删除(download-and-delete mode)，这在某些情况下不太方便，因而POP3进行了一些扩充(download-and-keep)。 另一种协议是IMAP，比较复杂，他将每个邮件和文件夹联系了起来，这样就不会有读取完删除在另一台PC无法看的问题了。另一个特点是IMAP运行用户获取邮件的一部分信息，比如只获取header。 用户在PC上运行用户代理，理论上讲，邮件server可以在他的PC上，单这要求他的PC一直不关机，所以通常的办法如上图所示。需要注意的是，SMTP是一个push的协议，所以对于图中Bob的server端到Bob的用户代理，不能用SMTP。这部分通常用POP3，IMAP或者HTTP完成。 POP3是一个非常简单的协议，用户代理只有4个命令list,retr(获取),dele,quit。一个例子： C: list S: 1 498 S: 2 912S: . S: . C: retr 1 S: (blah blah ... S: ................. S: ..........blah) S: . C: dele 1 C: retr 2 S: (blah blah ... S: ................. S: ..........blah) S: . C: dele 2 C: quit S: +OK POP3 server signing off . 用来结束文件 POP3协议的一个特点是，只要用户从POP3服务器读取了邮件，这个邮件就会被删除(download-and-delete mode)，这在某些情况下不太方便，因而POP3进行了一些扩充(download-and-keep)。 另一种协议是IMAP，比较复杂，他将每个邮件和文件夹联系了起来，这样就不会有读取完删除在另一台PC无法看的问题了。另一个特点是IMAP运行用户获取邮件的一部分信息，比如只获取header。 2.4 FTP FTP:基于TCP，和HTTP部不同的是，FTP使用两个并行的TCP连接来传输文件，控制和数据。所以HTTP是 in-hand, FTP是out-of-band。另外FTP的data连接是不连续的，所以每次TCP只能传送一个文件；FTP server端必须维护用户的状态；FTP也是使用7bit的ASCII码，这让它容易阅读。 2.5 DNS DNS最主要的作用是将hostname翻译成IP地址，DNS实际上是一个分布式的系统，它通过一组DNS服务器来组成的，DNS同时还是一个用户层的协议允许host查询分布式系统，DNS协议是允许在UDP上的使用端口53。 通常，DNS和其他应用层协议相互配合，举个例子：当一个浏览器(HTTP 客户端)运行在某个host上，请求一个URL(如www.bit.edu.cn)，那么我们首先需要获得这个URL对应的ip地址才可以。 在用户的机器上运行DNS客户端程序 浏览器提取hostname(www.bit.edu.cn)给DNS用户端使用 DNS用户端给服务器发送一个查询命令 DNS服务器最终返回给客户端对应的IP地址 一旦浏览器从DNS接收到了IP地址，就可以和HTTP服务器建立连接了！(IP addr:80) DNS同时还提供了其他几种功能: hostname重命名(alias)，方便人们记忆 邮件系统重命名 分布式加载，一个hostname可以有多个IP地址与之对应，比如CNN，这样当用户进行查询CNN的IP地址时，可以返回其中某个IP地址，这样就可以减少访问时的阻塞了 DNS系统组成 DNS是一个分布式的系统，因为如果所有的映射都保存在一个server，这会带来很多问题。所以形成了如图所示的结构。一共有三种DNS服务器，root, TLD(顶级域名服务器)和authoritative(权限/权威域名服务器)。 DNS查询 如图所示，还有另一种回溯的办法，不过在实际中，是用上图的迭代法，准确来说:host到local DNS服务器是回溯的，其他的都是迭代的。 DNS cache 一般来讲，一个server可以保存一些过往的信息，比如local DNS可以保存TLDserver的地址，这样就可以绕过访问root了。 DNS服务器存储的是resource records(RRs), 一个RR由思源组构成: (Name, Value, Type, TTL) TTL是RR的生命有效期，先可以忽略掉。 一些常见的record: Type 意思 例子 A IP地址 (relay1.bar.foo.com, 145.37.93.126, A) NS 权威服务器 (foo.com, dns.foo.com, NS) CHAME 主机的规范名字 (foo.com, relay1.bar.foo.com, CNAME) MX 电邮交互名字 (foo.com, mail.bar.foo.com, MX) DDoS 由于DNS比较脆弱，引申出了很多对于DNS攻击，一种方式是通过大量请求，已达到使那些真正的请求被搁置。不过这容易被DNS cache解决掉，另外通过packet filter也可以解决。另一种方式是欺骗方法，攻击者发送一个假的回复给DNS server，使得server接受假的RR存储在cache中，这样就可以把目的的web引导到欺骗者的web上了。 P2P 目前为止介绍的这些应用如Web, email, DNS都是依赖于一个永远开启的服务器，不过P2P并不要求此，每一个peer都可以充当一个节点，可以与其他节点进行交互。 BitTorrent peer从其他peer每次下载一个数据块，大小是256KB，每一个torrent都会有一个跟踪器，用来记录在这个大区域中其他的peer信息。 这样如图所示，当一个新的伙伴(Alice)加入这个块时，tracker随机的选择一些peer，并且把这些peer的IP地址信息给Alice。于是乎，Alice就会去和他们进行TCP的连接，不过随着时间柳树，一些邻居会离开，一些新的邻居会加入，所以与之相交互的peer不断改变。 那么，在给定的任意时刻，每个peer都会有一个文件(假设Alice就请求这个文件A)的一部分内容(块),那么Alice需要去周期地询问她的这些邻居谁有她想要的块。这带来两个重要的议题: 哪个块请求的优先级最高 需要给哪个邻居最先进行请求 对于第一个问题，Alice会使用一个叫做稀缺优先的准则，举个例子，比如Alice一共有三个邻居，邻居A有块1,2,3;邻居B有块1;邻居C有块1,2，所以这个时候会先请求3。 对于第二个问题，BitTorrent使用了一个比较聪明的算法，基本的准则是给那些可以与Alice连接有快速率的更高的连接优先级。 DHT 哈希散列表 下面考虑如何实现一个P2P网络中简单的数据库，这个数据库会存储简单的(key,value)对，下面考虑一个例子。这里key是内容名字，value是peer的IP地址。 假如Bob和Charlie都有Linux发行版，那么就会保存为(Linux,Bob的IP)和(Linux,Charlie的IP)。然后Dave这里使用DHT存储了的信息，那么假设Alice想要获取Linux，首先她应该先获取这个DHT，这样她才知道要给谁请求，谁有Linux。所以实际上她会先去获取Dave里面的DHT的信息，然后访问Bob或者Charlie。 一种建立DHT的方法是Alice向所有的peer去询问谁有Linux，这听起来就很蠢。所以这里会有一种稍微优雅一点的方法，我们把N(4)个peer:Alice,Bob,Charlie,Dave可以映射成log2N个bit进行存储，(00,01,10,11) 这样一个自然的方法是每次都去寻找那个最近的节点，(当然他们在物理上可能很远)。 (懒得翻译了，感觉挺直白的) To gain some insight here, let’s take a look at a specific example. Suppose n = 4 so that all the peer and key identifiers are in the range [0, 15]. Further suppose that there are eight peers in the system with identifiers 1, 3, 4, 5, 8, 10, 12, and 15. Finally, suppose we want to store the (key, value) pair(11, Johnny Wu) in one of the eight peers. But in which peer? Using our closest convention, since peer 12 is the closest successor for key 11, we therefore store the pair(11, Johnny Wu) in the peer 12. 假设有一个peer, Alice想要插入一个pair到DHT中，她首先确定哪个标识符离得最近，然后她会给那个标识符(实际上是peer)发送个信息，告诉他存储这个pair。但是Alice怎么知道哪个peer离这个key最近呢，如果Alice知道所有peer的ID和对应的IP地址的话，那她就可以一下子访问到了，不过这在实际的大型系统也是不可能的，一种折中的方法是存储Log2N的pair。 2.6 视频流与CDN 2.6.2 HTTP流(HLS)和DASh 在HTTP streaming中，视频被简单地存贮在HTTP服务器中，就如同普通的文件，有一个对应的URL，当用户想看这个视频时，客户端建立一个TCP连接，并发送一个GET请求，然后服务器端返回这个视频文件(HTTP数据包)。 尽管HLS被广泛地应用，他还是有一些缺点的:所有的用户都接收同样的视频编码，即使客户端的带宽有很大的不同。这样就引出了一个新的方式，被称作DASH，动态的媒体流(依托于HTTP)。 在DASH中，视频被编码成不同的版本，每一个版本都会有一个不同的速率，对应于一个不同的视频质量。这样客户端就可以动态地在任意的时间进行选择(通过HTTP GET request) 2.6.3 CDN 对于视频公司而言，最直接地提供视频流服务是建立一个巨大的数据中心，并且在这个中心存储所有的视频，当客户请求某个视频时，直接从数据中心拿出来发送给用户。但是这样会带来三个问题: 如果客户端和数据中心离得很远，这个通信就会经过很多ISP，并且一些ISP可能分布于不同的国家，如果其中的某一个链路提供的吞吐量小于视频所需的速率，那么这个端到端的吞吐量就不满足要求了。 对于那些十分热门的视频而言，他们将会在同一个链路传送很多次，这会大大浪费网络带宽，对于公司(Google的Youtube)而言，需要支付更多的费用。 如果这个数据中心出现了问题，那么视频将无法被观看，因为他没有其他的分布式节点来保存这些信息。 为了解决单一数据中心的这三个问题，CDN的概念应运而生。CDN就是管理不同地域的服务器，并保存不同的视频文件(或者其他形式的web内容如图片),将每个用户的请求引导至合适的server，这样可以获取最大的用户体验。 CDN可以是私有的如Google用来分布式存储Youtube的，或者是共有的。 CDN通常采用以下两种中的一个部署思路: 更深层次: 在全世界接触ISP的地方部署服务器集群, 这个方法的思想是可以离用户更近，这样就减少了用户的延时并且提高吞吐量，因为用户到服务器的router和link被大大减少了。因为需要部署很多的服务器，所以如何维护和管理是一个比较大的挑战。 走进家庭: 将ISP服务带进各家各户，这是通过建立为数不多的(几十个)大写的集群实现。这些CDN并不深入ISP，而是仅仅将他们的集群部署在IXP(交换节点中),这种方式使得维护起来变得容易很多。 2.7 socket socket正如前面提到的，是通信的接口，下面以UDP和TCP分别为例，用实际的python代码展示socket的工作原理。 UDP socket 当socket建立时，客户端需要把服务器的端口和地址打包发送，另外客户端自己的端口和地址实际上也会打包发送给对方服务端。虽然加入客户端的地址通常不需要UDP代码(这一般都是由操作系统维护的)。 from socket import * ### client ### serverName = 'hostname' serverPort = 12000 clientSocket = socket(AF_INET, SOCK_DGRAM) #AF_INET 代表IPV4 SOCK_DGRAM 代表UDP message = raw_input('Input lowercase sentence:') clientSocket.sendto(message.encode(),(serverName, serverPort)) modifiedMessage, serverAddress = clientSocket.recvfrom(2048) print(modifiedMessage.decode()) clientSocket.close() ### server ### serverPort = 12000 serverSocket = socket(AF_INET, SOCK_DGRAM) serverSocket.bind(('', serverPort)) print(\"The server is ready to receive\") while True: message, clientAddress = serverSocket.recvfrom(2048) # 等待client传送 modifiedMessage = message.decode().upper() serverSocket.sendto(modifiedMessage.encode(), clientAddress) TCP socket from socket import * ### client ### serverName = ’servername’ serverPort = 12000 clientSocket = socket(AF_INET, SOCK_STREAM) clientSocket.connect((serverName, serverPort)) # TCP 首先和server建立连接 sentence = raw_input(’Input lowercase sentence:’) clientSocket.send(sentence.encode()) # 然后直接只传送数据 modifiedSentence = clientSocket.recv(1024) print(’From Server: ’, modifiedSentence.decode()) clientSocket.close() ### server ### serverPort = 12000 serverSocket = socket(AF_INET, SOCK_STREAM) serverSocket.bind((’’, serverPort)) serverSocket.listen(1) # 参数是等待的最大连接数 print(’The server is ready to receive’) while True: connectionSocket, addr = serverSocket.accept() # 接收到client的地址完成TCP连接的建立 sentence = connectionSocket.recv(1024).decode() capitalizedSentence = sentence.upper() connectionSocket.send(capitalizedSentence.encode()) # 同理，只需要将数据发送就可以，而不需要再发送地址了 connectionSocket.close() const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'computer-network-top2down', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitalk.render('gitalk-container') require(['gitbook'], function(gitbook) { const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'cyc10-rcore-tutorial', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitbook.events.bind('page.change', initMygitalk) function initMygitalk() { gitalk.render('gitalk-container') } }) "},"Chap3.html":{"url":"Chap3.html","title":"第三章：运输层","keywords":"","body":"第三章 3.1 运输层协议介绍 运输层协议协议提供应用进程之间的逻辑通信,所谓的逻辑通信是指从一个应用的角度来讲，host运行的进程仿佛是直接相连的那样，尽管物理层面上，他们可能相距很远。 正如上图中所示的那样，我们需要注意的另一点是网关只作用于网络层部分的datagram，他们并不检测封装在运输层的那些datagram。 运输层和网络层的关系 书里面举了一个形象的例子，我简化一下：假设小明一家10几个人住在中国，小张一家10几个人住在美国，他们是好朋友且用邮件通信。小明家的同学们把写好的信件交给小明家的看门大爷，由看门大爷收集分发。看门大爷只需要定器的把邮件给邮局送去，或者给邮递员送到邮局。同理小张家也是。 在这个例子中，邮递服务就是提供了一个逻辑链接，他是社区对社区的，而不是人对人。 对应的网络概念: 应用中的保文: 信件内容 进程: 写信的这些人 hosts: 小明一家,小张一家 运输层协议: 看门大爷 网络层协议: 邮递服务 运输层协议只负责把应用进程中的报文移动到万千网络中的一个小网络节点，在邮件中间传递的过程中，他们并不知道细节。就像看门老大爷不知道邮件是从太平洋到的美国，还是从大西洋到的美国。 实际上，开门大爷——运输层协议并不能保证什么，因为他会被网络层提供的服务所限制，如果网络层不提供贷款和时延保证的话，运输层的保障就无从谈起了。 不过，某些情况下，如TCP就可以在即使网络层协议不可靠的情况下也可以提供可靠传输。(?!目前还不清楚机理，神奇.jpg) 对于TCP和UDP来讲，他们最重要的责任是将IP的传送服务从system到system间提升到process到process间，我们把这种提升传输称为(de)multiplexing。 3.2 多路复用和解复用 对于计算机网络来说，多路复用和解复用是必须的。比如你有四个网络应用的进程正在运行，当你电脑中运输层接受到了来自网络层的数后，它需要将这些数据运送给这四个进程中的其中一个。 正如图中所示的那样，在接收端的运输层并不直接把数据传送给进程，取而代之地是一个中间的socket。每一个运输层的segment都拥有一系列的位用以实现复用和解复用。多路复用就是收集不同socket的数据块，把每个数据块和头部的信息(额外添加的)打包发送给下面的网络层。 多路复用需要(1)socket拥有唯一的识别符(2)每个段都有一些特殊的位用来告诉socket去向谁运输。这包括源端口号和目的地的端口号。0到1023的端口号是一些通用的，也就是说一般我们分配port的时候避开他们(RFC1700)。 需要注意的是，UDP socket是可以被一组(目标IP地址, 目标端口号)所完全识别的，结果就是如果两个UDP段拥有不同的源IP地址或者不同的源端口，但拥有相同的目标IP和端口的话，这两个段将会被直接运往到相同的目标进程(也是通过相同的目标系统的socket) 在这里，源处的端口号起到一个返回地址的作用 而对于TCP的socket来说，完全决定需要一个四元组(源IP地址，源端口，目标IP地址，目标端口);因而若两个TCP段拥有不同的源IP地址或源端口，他们将会被引导至两个不同的socket上。下图例子给出了很好的解释。 对于webserver来说，在socket和进程之间也不是一对一的，今日的高性能的Web服务器一般会为每个新的连接建立一个新的线程。对于那些不连续连接的HTTP来讲，依然会给服务器带来不小的负担。 3.3 拥有少连接的运输层协议:UDP 如果应用选择了UDP作为运输层的协议，那么应用几乎是直接地与IP对话。UDP在发送和接受运输层实体前并没有握手，因而UDP被称之为connectionless。 DNS就是一个典型的使用UDP的应用层协议，相对于TCP而言，UDP具有以下这些优点。 更好的控制什么数据传输，以及什么时间，对于UDP而言，当应用进程一把数据传输给UDP时，UDP就会把他们打包成UDP的段并且迅速的把这些段传递到网络层。TCP，拥有阻塞处理的机制。对于那些实时的应用而言，通常都要求一个最小的传输速率，并不想延时任何的传送，并且可以容忍一些数据的丢失，那么TCP就不是很适合这些应用了。 不需要建立连接。TCP需要使用三次握手在传输真正的数据之前。HTTP使用的是TCP，因为当你下载网络上的一些文件的时候，总希望他们是可靠的。不过QUIC协议(Quick UDP Internet Connection),在Chrome浏览器中使用的就是用的UDP作为运输层的协议，并且实现了应用层的可靠控制。 更小的头部，UDP需要8个字节: 2字节自己的端口，2字节目标的端口，2字节长度，2字节校验码;相比之下TCP需要用到20个字节。 实际上，即使使用UDP作为运输层的协议，在应用层的角度上保证传输可靠也是有可能的。比如说在应用层上加入确认和重新传输的机制。QUIC就是这么做的，不过那并不是一个trivial的工作:) UDP使用1补码的方式，前两个2字节相加得到一个16bit的数据，再和第三个字节相加，取反就是校验码了，所以接受的时候把他们都相加就是1111...了。 UDP之所以提供这种校验码的目的在于不一定所有的链路之间都有检查的功能，甚至即使这个数据被正确的传送到了数据链路层，那么在router里面转移存储的过程中也是有可能出现错误的。虽然UDP提供了这样检错码的机制，不过他并不提供恢复错误的功能，一些UDP的实现直接简单地舍弃了那些损坏的段，另一些则把这些错误的段标记为警告。 3.4 可靠传输准则(重要) 这部分是精华啊，认真看书,决定翻译全文! 在这部分，我们将更广泛的层面考虑可靠传输的问题，这是因为实现可靠传输不仅出现在运输层，并且再链路层和应用层也会用到。这个问题是网络技术上一个非常重要的事情。 +------------------------------------------------------------------+ | APPLICATION LAYER | | Sending process Receiver process | | ↓ ↑ | | | | | +----------|------------------------------------|------------------+ | | TRANSPORT LAYER | | | \\ +-----------------+ / | | ------>| Reliable Channel|-------> | | +-----------------+ | +------------------------------------------------------------------+ 上面说明了我们目前学习到的可靠传输的框架。这种抽象的服务提供给了更高layer的可靠保证。对于一个可靠的信道而言，没有任何一个bit会出现翻转的问题或者对视，并且可以按照顺序传递。这种服务也恰巧是TCP所能提供的。 实现这种服务并不是那么简单的，因为那些再可靠的传输协议下面的协议可能并非是可靠的。比如TCP是一个可靠的运输层协议，但是IP就并不是一个可靠的网络层的协议。 这这个小章节里面，我们将逐渐地开发发送和接收端的运输层协议，并且逐渐增加复杂度，举个例子来说，我们将考虑当信道会有误码或者丢失整个包的情况下，需要哪种机制。当我们讨论的过程中，我们假定包将会被按照顺序运输至目的地，尽管一些包可能丢掉了，也就是说包经过信道后并不会有错误的顺序。 +------------|----------------------------------|------------------+ | | TRANSPORT LAYER ↑ | | rdt_send()↓ deliver_data()| | | +------------------+ +------------------+ | | | Reliable data | | Reliable data | | | | transfer protocol| | transfer protocol| | | | (sending side) | | (receiving side) | | | +------------------+ +------------------+ | | ↑ rdt_rcv()↑ | | udt_send()↓ ↓ | +------------|-----------------------------------------------------+ | | | | | \\ +-----------------+ / | | ------>| Reliable Channel|-------> | | +-----------------+ | | | +------------------------------------------------------------------+ 如上面这个图所描述的那样,运输层的发送端将会被一个叫rdt_send的函数触发，这个函数将会把更高层的数据发送过来，(rdt 代表 reliable data transfer) ;在接收端，当一个包传送到目的地rdt_rcv会被调用,然后为了把数据继续传送给应用层，调用deliver_data。为了交换packet给更高或更低的层次，发送和接收端给另一端发送包是使用udt_send(unreliable data transfer)。 现在我们开始逐渐深入一些协议，他们将会逐渐变得复杂起来 理想信道下的可靠传输 rdt1.0 我们首先考虑最简单的情况，在这种情况下，其下面的信道是完全可靠的。在此基础上的协议我们称之为rdt1.0，这是一个很普通简单的例子。他的有限状态机如下: 由于它比较简单，看图就可以了，发送和接收都只有一个状态(并且在这里我们假定了接收端可以迅速地接收发送端的信息)。 信道有误码下的可靠传输 rdt2.0 一个更贴近真实情况的场景是packet中的某些bit可能会出现错误。这种错误在当今的网络下还是很容易出现的，比如在packet传递的过程，或者buffer的时候。在这种情况下，我们仍然将假定接收的包是按照顺序的。 在着手开展新的协议之前，我们首先考虑人们是如何应对这种情况的。在一个经典的场景下，接收消息的人会说\"好的\"来确保当前的话听懂了。如果他没有听懂，他会向你再询问，发出没听懂的意思比如\"你说什么\"。这种协议使用了积极认可(\"OK\")和消极认可(\"Please repeat\")。这种控制消息使得接收者可以让发送者直到当前的消息是否被正确接收了。也可以让发送者直到需要重新发送一遍。在计算机网络世界中，这种依赖于重传的机制称为ARQ(Automatic Repeat reQuest) protocols。 在ARQ下，我们需要实现以下功能: 错误检测，接收者反馈，重传，如下图所示，在左侧情况下，发送端等待高层数据传输，然后rdt2.0会把这个包加入校验码发给接收端，接收端会返回一个值，如果是NAK(代表有错误)就继续发送，如果没错误就返回最开始的状态，等待高层数据传输新的数据。接收端则是如果发现有错就返回NAK，继续等待；如果没错就把数据传给更高层的协议，并返回ACK信号。因为发送端必须等待接收信号确认才会发送下一个，这种协议也被称之为stop-and-wait协议。但这种协议对信道的利用率很低，并且如果ACK或者NAK有错误的话就会有问题。 解决ACK/NAK错误的一种方法是接入足够多的检测位,另一种是无论接收到一个错误的ACK还是NAK，都进行重新发送。这种方法的难点在于接收端不知道上个ACK或者NAK信号有没有被发送断正确接受，所以他事先并不知道将要到来的包是新数据还是重传的。 解决这种方法是使用sequence number。这样接收端只需要检查这个序列号就可以知道这个收到的包是否是重传的了。对于这种stop-and-wait协议来讲，一个序列号就足够。接收端会把最近接收到正确的sequence number发送回发送端，发送端只要比较序列号是否一致就可以了。 发送端的状态如下：1. 发送端高层layer的发送，整理数据添加checksum，并添加序列号为0，发送给接收端，接收端收到信号后如果有问题就会要求重传(如果seq number 有问题也是) 2.经过若干次重传或者直接ok，跳到下一个状态，这时发送端发送序列号为1的包，如果接收端发现序列号错误或者包错误，还是按照要求重传。 取代发送NAK，我们可以发送一个最近的正确包的ACK，这有相同的效果，如果发送者发现有两个相同的包被接受，就说明出现了问题，就像rdt2.2所示： 在rdt2.2中，并没有NAK信号了，取而代之的是如果当前发送的是序列0，我就返回一个序列1，这样发送端就知道发送的那个包出现了问题。 在丢包情况下的可靠传输 rdt3.0 在当今的网络环境下，丢包其实是经常发生的，两个额外的考虑必须增加：1.如果检测包丢失 2.当包丢失时需要做什么 这里我们先把检测和恢复的任务放到发送端。假定发送者发送的那个包或者接受者对那个包的响应，丢掉了。在这种情况下，发送端将不会接收到来自接收端的回应。如果发送端等待的时间足够长了，那么发送端就确信，这个包丢失了，所以需要重传。但是究竟需要等待多长时间其实很难计算。 一个包实际上可能经过很大的延时，所以发送端可能会再次发送相同的请求即使这个包和ACK没有丢失。在这种情况下重复数据包会被发送到信道中，幸运的是在rdt2.2中我们已经有序列号实现了相关功能。 从发送者的角度来讲，重传是一个万能药，发送者并不知道数据包是否丢失，或者一个ACK丢失。实现一个基于时间的重传机制需要定时器来打断发送者。因而发送者需要1.在每个包(无论是第一次还是重传)发送的时候开启一个timer，2.响应时钟中断3.停止定时器 下面是一个rdt3.0的发送端的示意: 流水线式的 rdt3.0 为了提高信道的利用率，我们不再使用stop-and-wait的模式，而是发送者会发送多个包而不等待响应。这对协议有了新的要求: 序列号必须增加，因为每个发送的包都需要有一个独特的序列号，所以0-1序列号不够了。 发送和接收端必须有能力buffer更多的包，至少发送者可以将那些已发送并且还没有ack的包buffer住。 选择合适的错误恢复方法:GBN或SR GBN(Go-Back-N) 在GBN模式下，发送者可以发送多个包而不必等待回应，但是并不能超过一个最大的数值N，N代表那些流水线中未被ACK的包 上图中展示了一个基本的GBN序列号示意图，base指向了发送但还没被接受的最远处的包。nextseqnum指向还未发送但是在窗口里面的下一个包。N又被称作窗口大小，GBN也被称为滑动窗口协议。对于为什么把那些已发送而未被ack的包也计算在内，这一方面是出于流控制，另一方面当我们学习TCP的阻塞机制时也会明白了。 在实际运用中，一个包的序列号是储存在包头部的一个固定长度里面，如果k是这个域的总bit数，那么序列号就是[0. 2k-1]了，对于有限的序列号而言，所有的关于序列号的操作必须进行2的k次方取模。TCP拥有一个32位宽的序列号域(TCP是以byte为单位，而非packet)。 下面是发送端的情况: GBN必须可以被三种事件触发: 被更高层layer的调用, 发送端首先要检查窗口是不是已经满了，即使这里面有N个已发送未ACK的包。如果窗没有满，一个包就产生了并且被发送了，发送端的变量更新：如nextseqnumber++。如果窗口满了，发送端就会简单地把数据重新返回给更高的layer，这意味着告知高层当前窗已经满了。更高层将会在过一会去重新尝试。在一个实际的实现中，发送端可能会要么是缓存这部分数据，要么是有一些同步机制，使得高层的layer调用rdt_send当且仅当窗口不满。 ACK 在我们的GBN协议中，一个对包n的确认将被视作累积的确认，意味着前n个包都是被接收端正确接受的。 超时重传 如果timeout发生了，那么发送者就会重新发送所有已发送的但是还没有被确认的包。 对于GBN来说接收端其实还是比较简单的。如果一个包(序列号是n)正确的接收了，并且是按照顺序(也就是传送给高层的上一个包的序列号是n-1),那么接收端就会发送给发送端响应一个ACK，并且把包的数据(除去header等)发送给高层。在其他的所有情况下，接收者直接丢弃这个包，并且发送ACK(只是这个ACK对应的序列号是最近接收并且是正确的那个)。 在我们的GBN协议中，接收端丢弃那些顺序不正确的包。尽管这看起来十分的愚蠢和浪费直接丢弃那些正确接受的包裹。对于接收者来说，他们只需要保留seqnumber的下一个顺序的包就好了。而发送端则需要buffer窗口N下所有的packet。 实际上GDB协议包含了几乎我们目前学到的所有的技巧，包括使用序列号，累计认知，校验，超时重传。 Selective Repeat GBN可以让发送者充分利用流水线的功能，但是GBN本身也面临着性能的缺陷问题。实际上，当窗的大小和带宽延时都比较大的时候，许多包都有可能在流水线中。一个很简单的包错误就会导致GBN重传一大部分包，很多都是不必要的。 正如所命名的那样，Selective Repeat可以避免一些不必要的重传，仅仅对那些拥有错包或者丢失的重传。这就是的接收方需要记录窗口中每个包的状态。 SR接收端将对那些正确接受的包(无论是否是顺序的)都会进行相应。那些顺序错误的将会被buffer直到任何丢失的包(packet拥有小的序列号)被接收。 SR发送端的事件和动作： 从更高层的layer接收到数据，SR此时会检查下一个可用地序列号。如果这个序列号在发送者的窗口里面，这个数据就会被打包并且发送，否则告诉高层被缓存了或者请求过一会再传送。 超时 定时器再一次地被使用，只是这次每个包都必须拥有各自的逻辑定时器。 对ACK的响应。 如果ACK受到了，SR会标记那个包是已经收到了(假定他在window里).如果包的序列号等于base，那么window就会向前移动，直到一个未ACK的包。 接收端的事件和动作: 如果是序列号为[rcv_base, rcv_base + N - 1]且正确接收的包。在这种情况下，接收端会返回给发送端一个ACK(带有特定的序列号)，如果这个包之前没有被接收过，那么它就会被缓冲。如果这个包的序列号等于接收窗口的base，那么这个包，和之前所有buffer的包都会被发送给上层。然后窗口向后滑动。 接收到[rcv_base-N, rcv_base - 1]序列号的包且没有bit错误的话，也要返回一个相应的ACK。(因为收发两端的窗口可能不同步) 其他情况下,忽略包。 下面是一个很生动的SR模式的流程 实际上缺乏同步机制会产生一些其他的后果比如当我们需要面对一个有限的序列号时。假定我们只有4个序列号，窗口容量是3。假定0-2的包裹都已经被正确的传送了。这个时候接收者的窗口时4-6，拥有序列号3,0,1。考虑第一种场景:ACK丢失了于是发送者重新传送这些包。因而接收者下次会收到包裹有序列号0，也就是第一个包的重传。此时接收端会收到第1个包序号0的重传。 第二种情况是前三个包的ACK均被正确地传送了。于是发送者的窗口也挪到了第4-6的包,序列号是3,0,1(注意此时发送接收都是3,0,1)，然后此时发送序列号为3,0的包(也就是第4第5个),不幸的是，序号3丢失的，所以在接收端直接收到了第4个包序号0的发送,可是对于接收端来说，他怎么知道这个包是不是重传的第1个呢?亦或是一个新的包。 事实上应该满足:windowSize 我们其实假定了这些包并不可能会出现乱序的情况。当然了，当发送端和接收端被一个物理线连接的时候，我们可以自然地给出这种假定。不过，当一个信道连接的是复杂网络，乱序包就会可能出现。一种问题是，可能一个序列号x出现在这个信道中，但是甚至并不在收发两端的任何一端的窗口中。一种方法是，只有当发送者确定先前的序列号x不在网络里面了的时候发锁着才会发送包x。这通常是以包不可能在网络中存活一定时间来实现的。对于TCP来说差不多是3分钟。(好像也挺久了的) 这节很重要，要仔细再看看！ 3.5 TCP TCP是一个基于connection的协议，因为应用进程在发送数据之前，两个进程必须首先和对方进行握手，TCP两端的变量都会进行一系列初始化的工作。TCP知识运行在两个终端系统上的，所以中间的router之类的实际上并不包含任何的TCP连接状态。 TCP连接提供全双工的服务，如果进程A和进程B之间有一个TCP的连接，那么A传B数据的同时，B也可以向A传输局。TCP连接也被称作点对点，因为他们是在单个发送者和接收者之间的。 三次握手的前两次并不携带任何数据，第三次可能会有数据包在其中。 对于接收端，实际上TCP会把数据发送到buffer中，对于发送端，TCP也会相应的把从用户端放入buffer的数据打包发送出去。不过对于TCP应何时发送buffer并没有明确规定。最大的数据包称作MSS，最大的传输单元容量是MTU，通常MTU是1500bytes，而MSS是1460bytes，另外40bytes是TCP/IP的头长度。 正如刚刚所讨论的那样，TCP拥有头部和数据两部分，当TCP需要传送一个比较大的文件时，比如网页的一个图像，通常它会被分散成多个大小为MSS的数据块，除了最后一个一般比MSS小一点。不过，一般来讲，传输的数据块是小于MSS的，比如对于Telnet而言，其中的TCP数据块一般只有1byte。 TCP结构示意: header length field 一般是空的 options 一般是当发送者和接收者商量MSS或者窗大小的时候用 flag SYN,FIN,RST用来开始和结束TCP;ACK用来响应，PSH代表接收者应该立刻将数据传送给高层；URG代表这个数据是紧急的，不过一般PSH，URG都不用。 最重要的TCP头部信息就是序列号和确认号了。这些位是TCP可靠传输的基本。TCP把数据看作是按照一定顺序排列的byte。假设传输一个文件拥有500k bytes，MSS假定为1000 bytes，所以序列号如下图所示: 也就是说这个一个段的序列号对应的是其所包含的第一个字节的序号，对于第一个段序列号是0，第二个段序列号就是1000 ACK序列号实际上是所期望的下一个序列号，举个例子，假设A接受了从B发送的0-535byte，并且马上要给B发送一个segment。因而HostA在等待字节536，所以A把536放到ack里面然后把它送回B。 因为TCP仅仅会发送ACK对应的是数据流中下一个缺失的字节，因而TCP又被称作提供累计确认。 这是一个telnet在收发两端的示意图，虽然由于telnet不提供加密逐渐被ssh取代，但是他基于TCP仍然是一个很好的学习的例子。假设用户端和服务器端的序列号初始的分别是42和79，当TCP连接建立后，用户发送seq=42,ACK=79,data='C',服务器端正确接收后，返回seq=79,ACK=42,data='C'，然后用户返回seq=43,ACK=80确认这个消息收到了。 TCP就像我们之前讨论过的rdt协议一样，使用超时重传机制来恢复那些丢失的数据。虽然这个概念比较简单，但是确实有一些微妙的问题等待我们去解决，首先是如何确定超时的时间阈值，当然这个时间肯定是要大于RTT，如果小于RTT的话，不必要的重传也会发生。 首先我们给出一个概念SampleRTT，代表一个客户端段发送一个段到接受这个段的时间，大多数的TCP实现并不是对每个段都测量这个SampleRTT，而是只测量一个已发送但是没有ack的段，大概每次RTT会产生一个新的SampleRTT。并且，TCP并不会对那些重传的段计算SampleRTT。因为router中可能出现阻塞，所以SampleRTT在段与段之间来回波动。为了更好地估计RTT，需要对这些SampleRTT进行某种程度的平均。TCP这里维护了一个平均值，称作EstimatedRTT公式如下：EstimatedRTT=(1−α)⋅EstimatedRTT+α⋅SampleRTTα一般是1/8。对于那些较近的SampleRTT，比重更大。相对于SampleRTT而言，EstimatedRTT要平滑地多。 此外，测量RTT的变动程度也是有价值的，这个值称作DevRTT，表示SampleRTT和EstimatedRTT的误差有多大。公式如下: DevRTT=(1−β)⋅DevRTT+β⋅|SampleRTT−EstimatedRTT|β一般取作0.25，如果SampleRTT波动很小，那么DevRTT就会比较小，反之会比较大。 这带来了一个新的问题，我们有了EstimatedRTT和DevRTT，那么究竟重传的时间限是多少呢？这个时间应该比EstimatedRTT大，否则会有很多不必要的重传，但是也不能太大，否则TCP对那些丢失的包，响应的速度将会下降。所以听起来，这个时间应该是EstimatedRTT加上一些余量，这些余量就是DevRTT了。 最终的计算式如下： 一般而言，TimeoutInterval被初始化为1。此外，当一个超时发生时，这个值将被double,这样可以避免过早的超时现象(即此时包已经正确接收了，但是ACK还在网络中没有传回来，暂时的double，可以解决此问题)。然后一旦段被接受了，EstimatedRTT更新了，那就仍然按照原来的方式进行计算TimeoutInterval。 在我们先前的关于可靠传输的讨论中，我们一般把每个已被发送但还没用没有被ACK的段分配一个定时器，当然这在理论上很好，但是时钟管理也会带来很多其他的负担。因此推荐的TCP时钟管理仅仅使用一个重传的时钟管理单元，即使这里有很多没有被ACK的段。在这节的讨论中，只是用单定时器管理的模型。 首先，我们给出一个高度简化的TCP发送者，使用超时机制来恢复那些丢失的段，接下来再呈现一个使用多次确认和超时机制的模型。在接下来的讨论中，我们假定数据只在一个方向传输: NextSeqNum = InitialSeqNumber SendBase = InitialSeqNumber loop (forever) { switch(event) event: data received from application above create TCP segment with sequence number NextSeqNum if (timer not running) start timer pass segment to IP NextSeqNum = NextSeqNum + length(data) break event: timer timeout //超时的判断就是用刚才那个公式 EstimatedRTT+ 4DevRTT retransmit not-yet-acknowledged segment with smallest sequence number start timer break event: ACK received, with ACK field value of y if (y > SendBase) { sendBase = y; if (there are any not-yet-acknowledged segments) { // 所以实际上timer对应的是最远的那个未被ACK的数据 start timer } } break; } 即使这种TCP非常简单，实际上也会有一些微妙的场景 (1)A发送给B一个数据段，序列号是92，拥有8字节的数据，这之后，A等待B的回应，尽管B收到了A这个包，但是B对A的ACK确丢失了，在这种情况下，超时发生，所以A重新发送同一个数据段。当B发现这个重传时，由于此时B端的确认号是100序列号小于这个B的确认号，所以B直接回传一个ACK即可。 (2)A给B连续发送两个包，第一个包还是序列号92，长度8，第二个包序列号100，长度120。B同样都收到了这个包，并且发回给A了，但是呢由于网络比较拥堵，A在接收到这个ACK之前就已经超时了，所以A重新发送，这个时候只先重传92，然后重新开始timer，这个时候会收到由于网络拥堵迟来的ACK，这个时候只要ACK120在第二个timeout之前回来了，那么第二个包就不会重传。 (3)A发送给B两个端(同2)，B都正确收到了并且分别发出了ACK100和ACK120只不过这个时候ACK100丢了,ACK120回到了A(假定都在timeout内)，这个时候A其实就已经知道B收到了119之前的所有byte，所以A就不会重传任何包。 double 超时时限 现在我们讨论一种大多数TCP都会使用的机制。当超时发生时，TCP重传哪个拥有最小序列的包。但是每次重传它会被时间设置为两倍先前的值。不过当重传的这些包被正确ACK之后，超时的时限又会由EstimatedRTT和DevRT决定了。 这种方法在拥堵控制上有一些作用，如果source不停重传包的话，拥堵会更加严重，所以TCP会延长(double)这个时间从而减小线路的拥堵。 快速重传 由超时引起的重传实际上也会带来一个问题，那就是端到端的延时还是比较长的。不过幸运的是，通常发送者可以在超时之前检测到包的丢失，这一般通过重复ACK来实现。 这个表格踪迹了TCP接收端的产生ACK的准则: event TCP Receiver Action 接受到的包对应期望的序列号并且之前的数据都被ACK了 延时ACK，等待最多500ms用来等待另一个顺序的包， 如果下一个包没有在这500ms到来，就发送ACK 接收到的包对应期望的序列号但是一个其他的包正在等待传输ACK 发送单独的cumulative的ACK ?? 接收到的包超过期望的序列号 (这部分称为gap) 迅速发送多个ACK，表征下一个期望的序列号 ?? 接收到的包在gap中 立刻发送ACK 好吧上个表我也没太搞懂，还是看图吧: 当发送第二个包的时候丢失了，第一个包接受的时候发送断开启计时(因为此时包2,3,4,5都还没收到)，此时第一个被正确接收之后，接收端由于一直没收到第二个包，又由于累计确认的缘故，只会发送ack100,当发送到第三次的时候，发送端就会触发快速重传了，重新发送包2。 3.6 阻塞控制准则 我们先前提到，在实际上，丢包一般来自于router的buffer不够了，网络也就拥堵了。重传是解决拥堵的办法，但重传并不是引发网络拥堵的根本方法——太多的源同时试图快速地发送数据。 3.6.1 阻塞的原因和代价 情景1:两个发送者，router拥有无限的buffer容量 假设AB以固定速率λ发送数据(从host到socket)，并假设下面的传输层十分简单，数据并不会有错误检测和流控制等。这样忽略了额外的头部信息的话都，并且他们都需要通过一个最大速率为R的router，那么实际上最终到达CD端的速率就等于λ，当发送端速率超过R/2时，实际上接收端不会再增加了，还是R/2。而对于时延来讲,当接近R/2的时候会急速上升，因为包在buffer会一直处于等待。 情景2:两个发送者，router拥有有限的buffer容量 现在我们假定这个链接是可靠的，也就是说会有重传的现象发生，因而，实际的λ`(offer load)并不是λ而是还会有重传的部分。最实际的情况是，发送者会出现一些过早超时的情况，并且会重传那些实际上并没有丢失的包。如果假定每个包都是重传了一次的话，最终吞吐量会降到大概R/4。 情景3：四个发送者，router拥有有限的buffer容量和多个路径 假定所有的host发送数据的速度都是λ，并且所有router的连接速率最大是R bytes/sec。 下面分析下A->C，这个路径会通过router R1和R2。A->C 和 D->B连接分享R1, 和B->D连接分享R2,如果λ比较小的时候，buffer的溢出发生的概率会非常少，这个时候吞吐量大概和最大负载差不多。 但如果λ比较大了，这个时候对于R2来说，B->D的流量会远大于A->C(因为靠的近？)，因为A->C和B->D必须竞争这些有限的buffer空间，所以A->C流量将会获得越来越少的buffer空间。在这种限制下，最终R2将不会得到任何的空间，这些缓冲空间将全部被B->D占据。 让我们再来回顾一下最后的情景，当一个包在第二个router下丢失的时候，实际上对于router来讲，他的工作也是无用的。这样实际上还不如直接丢掉这个包。所以我们这里看到了另一个由于丢失包造成的拥堵——他会导致前面所有router做的工作都白费。 3.6.2解决拥堵的办法 在这里，我们先简单的探讨一下，并根据网络层是否显式地提供解决运输层拥堵作为区分。 端到端的拥堵控制：在这种情况下，网络层并不提供一些显式地支持，对于IP而言，他并不需要提供这种机制，TCP处理拥堵的方法是减少窗口大小。 网络层帮助解决拥堵: 有了网络层的帮助，router会提供一些反馈，告知目前网络的拥堵状态，这种反馈可能仅仅是link中的一个bit，复杂一点的，可能是告知发送端，router可以保证的最大传输速率。实际上对于互联网默认的IP和TCP而言，采用的是端到端的方法，不过最近IP和TCP都选择性地实现了辅助解决的方法。 对于网络层协助的情况，第一个情况可能是直接把信息从router发回发送端，第二种，也是更寻常的是，由接收者告知发送端阻塞的情况，第二种发送会用到整个RTT时间。 3.7 TCP 阻塞控制 TCP必须提供端到端的阻塞控制而不是基于网络层协助的阻塞控制，因为IP层一般而言不提供显式地反馈。 对于TCP而言，他控制阻塞的方法是控制发送地速率，这引发三个问题 当检测到阻塞时TCP如何限制他的速率 TCP如何预知网络中出现了阻塞 采用什么算法来改变发送速率 对于TCP而言，收发两端都有两个bufer，分别供发送和接收使用，TCP机制需要让发送端维护额外一个变量，称为阻塞窗口,cwnd。特别地发送端没有被确认地(但可以发送/或已经发送的)不能超过cwnd和rwnd的最小值。 rwnd和buffer容量比较相关，这里为了主要探讨阻塞控制所以我们假定rwnd一直都满足rwnd > cwnd，就是不考虑rwnd的影响了。 所以发送端可以通过限制这个cwnd来限制那些未被确认的数据包的多少，进而间接地控制发送端速率。不考虑包丢失的情况下，发送端的速率是 cwnd/RTT bytes/sec. 下面考虑第二个问题，当出现timeout或者三个重复ACK的情况下就代表了一个丢失事件了。 一些准则: 一个丢失的包暗示阻塞，所以TCP发送端的速率会被降低。 一个确认的包代表网络畅通，所以发送端速率可以被增加(ACK对应的序列号是未被ACK的包) 带宽探测：当可以收到正常的ACK时发送端会逐渐增加速率，直到出现丢包。然后再降低速率。从某种程度上说像是个贪心即尝试以当前速率发送，如果正常，再快点，如果不行，就慢点。 TCP阻塞控制的三个算法 1.慢开始 2. 避免阻塞(CA) 3.快速恢复 前两个是必须的，第三个是推荐的但不必要 慢开始 当TCP开始建立连接的时候，cwnd是初始化为1MSS，所以开始的发送速率大概是MSS/RTT。由于网络带宽可能远大于这个数值，因而cwnd此时会快速增加，具体说来就是每接收一个ACK就会增加1个MSS，造成的结果是每个发送序列(谢希仁)后就会加倍。 书中说每个RTT后就会double,个人感觉不很严谨 这个过程不会维持很久，因为网络带宽不是无限大的，而且这个阶段发送速率基本上可以说是指数增长。所以当遇到超时/三次重复确认后，就会减缓cwnd了。具体说来： 对于timeout而言，cwnd立刻被设置为1，并重新进入慢开始阶段，并且把慢开始门限设置为cwnd(之前的)/2。 对于可能cwnd直接达到门限值的情况而言，就会进入CA模式，这个时候TCP线性的增长cwnd。 对于三次重复确认而言，TCP会有一个快速恢复的过程，这个时候同样会把门限值设置为cwnd/2，而cwnd此时不再设置为1，而是门限值(ssthresh) + 3MSS 上面这个图就是这个过程，个人认为还是非常的清晰明了的。 CA 进入到CA模式后，cwnd会小心的增加，每次收到ACK的时候，cwnd会增加MSS/cwnd，举个例子，假如现在MSS是1460bytes,cwnd是14600bytes，所以10个包被发送，每个ACK只会增加cwnd,1/10个MSS。相当于过一个发送序列后，cwnd只会增加1个MSS。 当出现超时的情况下，再CA模式下和慢开始模式下的处理是相同的。 快速恢复 进入到这个模式的是，cwnd仍然以指数方式增长直到一个timeout 下图是TCP Tahoe和TCP Reno的比较 一开始，慢开始门限都被设置为8,当达到这个门限时，两种方法都是随着RTT增加而线性增长，不过不同的是，当出现一个重复包的情况时，(此时MSS = 12)，在Tahoe方法下，ssthresh被设置为6MSS, cwnd设置为1，重新进入慢开始阶段；而在Reno方法下，cwnd被设置为9MSS然后线性增长(直接进入CA模式)。 简单的总结下，TCP阻塞控制通常也被称为AIMD(additive-increase, multiplicative-decrease), TCP 吞吐量 (忽略慢开始阶段)设TCP cwnd仍然线性增长时的最大包的数量为W,那么TCP发送速率大概会在 W/2 RTT ~ W/RTT之间。平均下来，TCP吞吐量是 0.75W/RTT 3.7.1 公平性 假设有K个连接共享某个链路，每个连接都会平均的得到R/K的带宽。 在TCP AIMD的算法中，不同的TCP连接可能开始于不同的时间，并且会有不同的窗口大小，不过他们还是会最终公平地享有相同地带宽。 我们考虑这样一个场景，假定两个TCP连接共享一个具有传输速率为R的链路，并假设这两个连接有相同的MSS和RTT，这样如果他们有相同的cwnd，他们就会有相同的吞吐量。并且没有其他的TCP连接或者UDP数据通过这个链路。并忽略慢开始的影响并假设TCP连接始终处于CA模式。 如上图所示，假定一开始链接1和链接2位于A，此时1的吞吐量比2的大，由于此时他们两个链接加起来的吞吐量仍然是小于R的，所以此时cwnd仍然增加，发送速率也会线性增加，假定到B的时候出现了丢包，这个时候链接1和链接2都会使他们的窗口大小减半，这个时候到达C点，反复这个过程，直到他们的吞吐量和 y = x 重合。 实际上呢，多个链接共享相同的瓶颈链接时，那些拥有更小RTT的连接会得到更多的带宽。 3.7.2 ECN(network-assisted congestion control) 网络层可以显式地为运输层提供阻塞信号，这种方式被称作ECN，在网络层有2个bit(一共是四种可能的取值)来提供这种服务，这2个bit存储在IP的头部，一个bit表示是否阻塞，另一个比特表示收发两端是否可以开启了ECN功能。 实际上，RFC并没有一个明确的规定表示router此时阻塞了，这个标志位仅仅会被router来决定。 const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'computer-network-top2down', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitalk.render('gitalk-container') require(['gitbook'], function(gitbook) { const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'cyc10-rcore-tutorial', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitbook.events.bind('page.change', initMygitalk) function initMygitalk() { gitalk.render('gitalk-container') } }) "},"Chap4.html":{"url":"Chap4.html","title":"第四章：网络层","keywords":"","body":"第四章 网络层:数据层次 4.1 网络层概述 首先需要注意的是，和运输层协议不同的是，网络层在每一个router内都是存在的。对于数据层次来说，每个router都需要将先前链路的数据发送至输出接口的链路上；而对于控制层次来说，最主要的工作是协助这些当地的每个router的传送数据，确认相应的线路。 4.1.1 forwarding 和 routing: 数据和控制层次 网络层的协议看起来蛮简单, 就是把包裹从发送端传递到接收端。 Forwarding: 把包裹发送到合适的linker上 Routing: 决定正确的路线使得包裹可以正常地从发送端传送到接收端 Forwarding 和 routing 这个概念一般混在一起，(个人理解也是这样), 不过Forwarding一般都只需要很短的时间，这一般都是由硬件实现的，而routing则会占据更长的时间，并且通常由软件来维护。 对于每个网络的router来讲，最重要的是forwarding表，根据达到的包的头部与这个表，router就知道要把数据分发到哪个下一级链路了。就像下面这个图: 在上面这个例子中，routing的算法存在于每个router中，并且在router中有相应的forwarding和routing的功能。这个routing算法是可以通过和其他router里面的routing算法通信，并计算forwarding表。 如果所有的表都可以直接地被人工地确认更新，这样的话就不需要任何routing协议。 控制层次: SDN方法 实际上一种更为广泛的方法，是通过远程的控制器计算更新forwarding table，如下面所示： 需要注意的是，尽管forwarding table更新的方式不同，但是他们二者的数据层次是一致的。 所谓SDN就是software-defined network，软件定义是因为控制器计算这个forwarding table并且这个控制器controller是由软件实现的。 4.1.2 网络层服务 一般来讲，网络层可以提供的服务如下: 可靠性 可靠性且延时不超过一定数值 顺序的传送 最小带宽以下保证正确传输 安全性(加密) 互联网提供的是非常简单的服务模型，通常被称为最大努力服务。在这种情况下，包裹的服务可以被认为是无服务的。 通常来说，router包裹根据目的IP地址来选择合适的link，更一般地是可以根据一些头部数值来选择合适的端口。包可能被阻止传递，或者重复发送，或者一些header值被重新改变。这些都是通过软件操作的，这也是SDN的核心所在。 一些交换包，被称作链路层交换(交换机?)，这是因为他们是根据链路层的数据来就行分组交换的(所以也被称作链路层(2层)设备)。其他的包裹交换，称作router，是根据网络层中的头部信息来进行转发决定的, 所以他们也被称为网络层(3层)设备。 4.2 Router里面有什么 这是一个路由器结结构，主要组成有: 输入端口，将物理链路层接到路由器的物理层，这就是输入端口最左侧和输出端口最右侧的功能。输入端口扮演了链路层的功能，用来和链路进行交互，这是输入输出端口中间方框的功能。最重要的是查找的功能，这是输入端口最右侧的功能，通过查询转发表决定路由器的输出端口。包含有控制信息的包被转发给路由选择处理器进行下一步处理。 注意此时的端口是物理的输入输出接口，和软件中的端口号是完全不同的概念。实际上的端口数量可能有几百个并支持10Gps(甚至几十Tbps)的传输速度。 交换结构，连接路由的输入和输出端口 输出端口， 输出端看存储着从交互结构发来的包并把这些包传输到链路(输出端口需要实现一些必要的链路层和物理层的功能)。 路由选择处理器，这个处理器完成控制层面的功能。在传统的路由中，他执行一些路由选择的协议，并且维护一些路由查找表和链路状态信息，并且计算转发表。在SDN路由中，路由选择处理器是和远程控制器进行通信的，这是为了从远程的控制器接受最新的前向转发表。 一个路由的输入端口，输出端口和交互结构通常由硬件实现。这是为了速度的考量。 在我们深入探讨router之前，先看一个小例子，假设交互是一个环形路口，汽车进入环形路口时需要一些处理过程: 基于目的地的转发: 假设汽车停到了任何一个停车站，并告知了他的最终目的地，一个服务员在这个停车站查找这个终点地址并决定这个环形路口的出口，告知这个司机去哪个出口。 更一般地转发: 服务员可以根据其他的一些因素(除了目的地以外)决定这辆车去哪里。比如汽车的来源地，汽车拥有的licensen等。来自于某一块区域的或者具有某一类状态的可能会直接地使用某一个特定的出口。 在这个比喻中，入口道路和入口的车站就是输入端口，环形路口对应于交换结构，出口道路对应于输出端口。 4.2.1 输入端口过程和基于目的地的转发 一个更为仔细的输入流程如下图所示: 需要注意的是，前向转发表是从转发处理器复制过来的，这通常是通过一个分离的总线(如PCI)。通过这种浅拷贝，转发的决策可以被每个router各自产生,而并不需要和中心的处理器进行交互，这样避免了中心处理器的瓶颈问题。 一个简单的前向转发表是每个IP对应一个转发方式，但是由于需要记录太多的地址(4billion for 32bit)，所以这种方法并不可行，可以通过前缀的方法来进行判断。比如下面这个图: 有时会出现一个值可以匹配多个prefix，这个时候需要匹配更长的前缀。比如 11001000 00010111 00011000 10101010 匹配的是link 1, 而不是2。 这样看来这个寻找的过程比较简单，但是当需要满足的传输速率很高的时候，就需要很小的延时才可以保证。所以lookup的过程必须由硬件来实现，而且简单的线性查找就不太满足时间要求了。对于内存访问时间我们也需要额外的关照，所以我们需要使用SRAM(作为DRAM的cache)。在实际工程中，TCAM(三元组)通常用于查找，在TCAM中，32位的IP存储在memory中，并以常数时间返回转发表中对应于那个地址的内容。 在一些设计中，一个包可以暂时地被交换结构阻止住，如果其他端口的包正在使用这个交换结构的话。这样一个blocked的包就会在输入端口进行排队等待，然后过一段时间会被调度到交换结构中。 lookup是一个很重要的动作，不过其他的一些也是很关键的: 1) 物理层和链路层的处理 2)包的版本号，检验和，存活时间 —— 这些都需要被检查，对于后两个，可能还需要重新修改。 在输入端口中，寻找目的地址进行匹配并让交互结构给指定的输出端口发送包是一个\"match plus action\"的动作。这个抽象动作在很多网络设备都存在，并不只是router中。在链路层切换中，也是有这种动作。 4.2.2 切换 通过内存切换，最简单早起的router都是传统意义上的乙酸计，输入和输出端口的交互都是通过CPU(控制处理器)的。输入输出端口就像是IO端口一样。在这种情况下，如果内存带宽是B个包/秒(读写都算上)。那么总的转发吞吐量小于B/2.另外需要注意的是，两个包不可能被同时向前转发，即使他们的目标输出端口不一样。因为只有一个内存写/读可以在系统总线上完成。 一些新近的处理器可能会使用一种类似于共享内存的技术，这样可以加快切换进度。 通过总线切换, 在有多个包请求的时候，除了一个包其他的都必须等待, 这样吞吐量会被限制在总线的速度上。尽管如此，这对一些小型区域的网络依然是足够了。 通过内部互联网络，这种会复杂一些。对于一个有N输入，N输出的端口来说，互联网络拥有2N的总线(好吧不是很懂)。这样的话可以支持并行地转发多个包。不过如果两个包从不同的输入端口传输到相同的输出端口，这样就必须等待。 4.2.4 发生queue的情况 包的排队情况在输入和输出端口都是可能发生的,当排队的现象更加严重的时候，就会出现丢包的现象了。 原文对排队做了好多解释，感觉没啥了解必要，跳过 4.2.5 包的调度 FIFO和优先队列(2个队列，一个优先级高)就不说了，下面说一下RR和WFQ，简单的RR算法和OS中的进程调度是一样的，一个广义上的RR队列是被称作WFQ(weighted fair queuing)如下图所示: WFQ和RR不同的是，每一个不同级别的流了可以接受不同数量的服务。 WFQ是一个基于Weight的公平队列，之所以说WFQ是公平的，是因为WFQ根据数据包的IP优先级来分配相应的带宽，优先级高的数据包，分到的带宽就多，优先级低的数据包，分到的带宽就少，并且所有的数据包在任何时刻都可以分到带宽，这就是它的公平之处。WFQ在根据IP优先级给数据包分配带宽时，是基于流（flow）来分配的。 4.3 IP协议 IP数据格式如下： Type of service. TOS用来区别不同类别的IP包，比如一些可能对实时性比较高的，有一些不需要那么高的实时性。 这样router就会有不同的策略。 包长度. 这个位长度一共是16，所以最大的包是64KB，然而一般不会超过1500B 标志位，分片偏移量 这些位是为了IP fragmentation Time-to-live. 这个位用来确保数据段不会被永远的循环，这个field会在经过一个router之后就减1，如果变为0了那么router就不再转发它了。 协议. 这个field一般只用于IP包到达最终目的地。比如值6代表这个数据通过TCP传递的，而值17代表这个数据通过UDP传递。 校验 关于为什么TCP/IP都要校验这里有两个原因，其一：只有在IP层中，IP头部才会被校验，而TCP/UDP的检查是对应于TCP/UDP的段。其二是TCP/UDP和IP并不需要都属于某个协议栈，比如，TCP运行在别的网络层上，然后IP的数据并不通过TCP/UDP IP有20字节的头部，而TCP也有20字节。所以对于一个datagram包含TCP段来说，一共有40字节的头部信息。 4.3.2 IPv4 分片 一般而言，一个链路层会有一个单次可接受最大的传输数据限制称为MTU，它要求IP的段不能超过一定的容量。这带来一个问题，不同的router之间可能使用不同的链路层协议，因为每个链路层协议的MTU可能不尽相同，所以当IP数据段超过某个router的最大容量的时候就会有问题。 解决的方法是将大的IP段分割成小的IP段，并把小的IP段重新防撞，然后发送，这些小的段就叫做fragment(分片)。 分片之后我们还需要重新收集起这些分开的片段，IPv4的设计这将重新收集的任务交给中断的系统而不是网络中的router。 当一个host接收到一系列的数据包时，它需要判断这些包是不是分片的，属于某个原来更大的包。如果这些包是分片的话，它还需要决定最后一次接收到片是什么时候。并且如何将这些片段拼起来。 为了完成这些任务，IPv4设置了标志位也就是刚刚图中的identification, flag 和 fragmentation offset位。当一个包发出时，发送端将识别号在这个包上盖了个戳。每次发送新的包，这个识别号就增加，当需要分片的时候，每一个小片都标记上原来的相同的识别号。这样接收方就知道哪些包是小片了。不过因为IP并不可靠，可能有的小片丢失了，为了确定接收方真的接收到了所有的包，最后一个片的flag为是0，而其他的片都是1。 另外为了让接收端知道传输过程中究竟哪个片丢了，offset位就会派上用场了。 4.3.3 IPv4 地址 每一个host端和router在公网中都必须有一个独立的IP值，在那些NAT中的不算。 左侧24bit都是相同的，在这张图中用交互机就可以连接。这个IP分配可以表示为223.1.1.0/24， /24又被称为子网掩码，告知最左侧24bit定义了这个子网络。 所以一般而言，一个公司拥有很多自网络，但他们都拥有相同的子网络地址。理论上不同的子网可以有不同的子网地址，在实际中，这些子网地址都很类似。 地址划分是由一个机构CIDR来完成了。一般的地址可以写作a.b.c.d/x，一般而言一个公司的IP拥有相同的前缀，只有这些前缀的位才会被公司以外的世界考虑。 所以对于router来讲只需要对特定的a.b.c.d/x存储一个entry就可以向公司中任何一个地址进行转发了。 剩余的32 - x用来分别公司内部的设备，所有的设备都有相同的前缀地址值，而根据这剩下的比特来区分私有网络中的设备。在CIDR之前，有一个经典版的地址分类，根据/8,/16,/24分成A、B、C三类IP网络。 不过CLASS C仅可以服务最多 256 - 2 = 254 个host，而B类最多65536个host又显得有些太大了。这就造成了资源的浪费。 另一种地址叫做IP广播地址255.255.255.255。当一个host给目的地址为255.255.255.255发送数据时，这个数据将会给所有子网络里面的host都发送。 如何获取地址 一个公司想得到一个IP地址，首先要和ISP对接，因为ISP拥有大量的IP地址。加入ISP拥有200.23.16.0/20，那么他可以分配比如8个地址: 200.23.16.0/23、200.23.18.0/23 ... 200.23.30.0/23，就像下面这个图所展示的那样。 DHCP 一旦公司得到了一组地址，那么就可以给host分配了，一般都是通过DHCP动态分配策略实现的。DHCP已经得到了很大的应用尤其是在无线网络，企业校园中。比如一个学生带着一台笔记本从宿舍走到了图书馆或者教室。那么在新的地点，将会连接到一个新的子网络并且有一个新的IP地址。 DHCP是一个客户和服务器交互的协议。对于一个新到来的客户，这个协议有四个步骤: 1.寻找DHCP服务器，由于host不知道DHCP服务器地址是多少，所以需要向255.255.255.255发送，端口号是67,此时由于host还没被分配地址这里姑且是0.0.0.0。 2.服务器提供IP，这个时候同样的需要返回255.255.255.255因为服务器并不知道客户端的IP，都是0.0.0.0。在这个返回的信息里面就有动态分配的IP地址，传输的ID号(和输入对应)和失活时间等。 3.DHCP请求 客户端host在收到服务器发送回分配的IP地址后(我的理解是可能有多个服务器都提供了IP，所以此时只针对某一个还需要再请求) 4.DHCP ACK 对于便携性而言，DHCP拥有很大的短板。具体说来就是TCP连接不能是远程的。 4.3.4 NAT(network address translation) NAT是负责一个子网络和外网交互，如下图，右侧是一个家庭网络，10.0.0/24，10.0.0.0是私有网络的三个部分中的一组。私有的地址表明这些地址仅仅对于那个网络中的设备才是有意义的。 实际上，每个家庭可能都会使用10.0.0/24，但是这些设备无法与公网通信，因为有成百上千的用户也是用相同的IP，所以这只对网络内部的设备有意义，而如果期望与外网通信，则需要NAT了。 NAT使能的router对外网来说就像是一个单一的设备拥有单一的IP地址。就像上图那样，对于公网来说router有一个地址138.76.29.7，但是公网并不知道router右侧的私有网络的信息。而外网的目的IP地址都是这个138.76.29.7,router需要将对应的包分发给对应的host，这就使用到NAT转换表了。 不过NAT也是优缺点的，端口号实际上应该对应的是进程，而不是host。因为使用NAT，一个host发送的port会被router重新定向到另一个新的port。 另一个问题是，router应该是网络层的设备，仅仅应该进行网络层包裹的运输，但是NAT破坏了合格规则，因为它相当于修改了源端口的IP地址。(好吧个人感觉也没什么大不了的) 4.3.5 IPv6 特点: 更长的地址范围: 128bits 有一个新的地址种类:anycast地址，允许数据包发送给一个组里面的任何一个host。 固定40字节的头部 流标记，区分实时性不同的包比如音视频和邮件。 具体格式如下： Traffic class: 如同IPv4中的TOS，用来给flow更高的优先级,或者给某些应用更高的优先级。 next header: 告诉协议那部分要被传送(如TCP/UDP)和IPv4一样 Hop limit: 每过一个router减1，到0就被丢弃 这些field被IPv4丢弃:分片、header校验、选择。 现在如果遇到过大的包直接丢弃，并且了为了速率的考虑取消了分片和校验的设置。header校验有些冗余。 IPv4->IPv6 通过管道的方式兼容，直接把IPv6的所有信息包括头部封装成IPv4的数据段: 网络层的协议短时间内很难再被改变了，应用层来说应该改变的更快一些 const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'computer-network-top2down', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitalk.render('gitalk-container') require(['gitbook'], function(gitbook) { const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'cyc10-rcore-tutorial', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitbook.events.bind('page.change', initMygitalk) function initMygitalk() { gitalk.render('gitalk-container') } }) "},"chap5.html":{"url":"chap5.html","title":"第五章：网络层的控制部分","keywords":"","body":"网络层：控制部分 5.1 简介 有两种可以控制转发表/流表，一种是每个router都有自身的控制器，另一种是通过远程的控制器。对于第一种来说，每一个router都有一个路由部分，可以用来和其他的router进行通信，从而确定转发表的数值。对于第二种来说，每个router里面有一个CA(control agent)，不过这个CA主要是用来和远程的控制器通信的，而且并不和其他的router中的CA通信。 5.2 路由算法 算法一：中心化算法——LS算法，需要获得所有节点和所有的边(权值) 算法二：去中心化算法——DV算法，没有一个节点拥有所有的路径信息。 第二种分类方法是根据算法是否是动态/静态，动态算法对路由成环/震荡更加敏感一些。第三种分类方法是根据是否负载敏感划分。 5.2.1 LS算法 LS算法需要拥有整个网络的节点和边，这通常是通过节点给所有网络中其他的节点发送信息完成的。实际中，这称作LS广播算法。LS使用的是Dijkstra算法 // 从u开始找 N' = {u} for all nodes if v is neighbor of u: then D(v) = c(u, v); // c(x,y)表示从x到y的距离，如果不存在这样一条路径，则是∞。 else D(v) = INF Loop find w not in N' that D(w) is min N' += w update D(v) for w's neighbor D(v) = min(D(v), D(w) + c(w, v)) until N' = all node 振荡: 考虑y->w的路径，选择是顺时针方向，因为1 y->z->w。现在都是顺时针了，然后此时逆时针路径空了，就又都变为逆时针了，如此往复。 一个可行的解决方法是并不是所有的路由都同时运行LS算法。不过研究者发现最终router会自己同步，所以即便他们在不同的时刻(有相同的周期)运行这个算法，振荡问题并不能避免。一个解决的方法是(随机化通知的时间周期)大概是这样，就是(让周期不一样个人理解)。 5.2.2 DV算法 DV算法，每个节点仅维护有限的信息:当前节点和所有邻居的cost以及，从邻居发送过来的信息 // if y is neighbor of x: Dx(y) = c(x,y) else Dx(y) = INF Boardcast neight loop wait until one path available for each y in N: Dx(y) = min(c(x,v) + D(v,y), Dx(y)) if change boardcast; 对于DV算法来说，cost变小，在网络中会被很快地传播，但是cost变大的传播速度会非常慢。一种解决的方法是posioned reverse，如果z通过y到达x，那么z会告诉y，z到x的距离是无穷大 LS和DV的比较 空间：LS需要O(NE)的信息，而DV只需要neighbor的。 时间：LS是O(N^2)的, DV是不确定的因为可能存在循环的问题，也可能会有count-to-infinity的问题。 健壮: LS只会算自己节点的信息，而不会影响其他的，所以还可以；而DV则会扩散错误，因为每个周期节点都会向他的邻居广播新的cost。 5.3 OSPF 目前为止我们学到的模型是所有的router都是一样的，他们执行相同的路由算法，并且通过整个网络的信息计算路由路径。但实际上应用中这个同质的模型会被简化，这出于两部分考虑： 体量 对于LS来说，每个router都储存所有的可能的目标是需要非常大的内存的。对于DV算法而言，传播到整个网络是在是需要花费太久了。 行政自治: Internet是ISP的一个网络，由ISP的router构建ISP的网络。那么每个ISP都希望这个网络中运行ISP指定的服务，或者对外隐藏一个内部网络，理想情况下一个组织应该可以按照他的想法操作这个网络，并且依然可以和外界的网络交互。 这两个问题可以通过AS(autonomous system)自治系统来解决，每个AS中有一组router，他们运行的是相同的协议。 OSPF就是一个运行在AS中的协议，他是基于LS算法的，每个router通知其他所有在AS中的router，并且即使链路状态没有改变，每隔一段时间也会广播一遍。 OSPF还具有以下一些特征： 安全性 OSPF的路由可以被验证，只有信任的路由才会被加入到OSPF协议中，这通常可以使用简单的密码和MD5完成。 多个链路 当源到目的地址有多个路径拥有相同的代价时，OSPF允许多条路径被使用。 继承 在一个AS中，路由可以继续被划分成多个区域，每个区域都运行自己的算法，每个区域中也都会有若干个router负责把packet传递到别的区域。 5.4 在不同ISP间进行routing：BGP OSPF是一个自治系统内部的协议，当一个包裹寻找路径的源和目的都在相同的AS中，这个路径将完全由内部AS协议决定。不过在AS之间则要采用另一种协议：BGP(Border Gateway Protocol)。BGP是一个十分重要的协议，因为它基本上可以说将成千上万个ISP连接了起来。 在BGP中，包裹并不是直接运送给特定的目的地址，而是一个前缀(?)，比如在BGP中，一个目的地址可能具有138.16.68/22的形式，这说明他可能包括1024个IP地址。所以一个路由的转发表将会有这样一个入口:(x,l)，x是一个前缀(138.16.68/22)而l是一个接口号。 BGP提供每一个router一个方法来： 从邻居自治系统中获取prefix可到达的信息 决定最好的路径 5.4.2 广播BGP路径的信息 对于每一个AS来讲，每个router都要么是一个网关router，要么是一个内部的router。网关router就是来连接其他AS中的router。下图中的1c和2a之间，2c和3a之间就是eBGP。 为了传播可以到达与否的信息，iBGP和eBGP的信息都将会被使用。举个例：传播一个可以到达路径的前缀x给AS1和AS2所有的路由。这种情况下，3a首先发送eBGP信息\"AS3 x\"给2c，然后2c给所有其他AS2中的router发送iBGP信息\"AS3 x\"，然后2a给1c发送EBGP信息\"AS2 AS3 x\"。最后1c使用iBGP发送\"AS2 AS3 x\"给所有AS1中的router发送信息。 在实际情况下，可能会有多种路径的存在，如下图所示： 5.4.3 选择最佳的路线 BGP里面有两个重要的属性：AS-PATH, NEXT-HOP。AS-PATH属性包含了一组AS，表征是如何传播的，就像刚刚所展示的那样。而NEXT-HOP是AS-PATH起始位置路由的IP地址。从AS1到x有两个路径，对于\"AS2 AS3 x\"而言，NEXT-HOP就是router 2a的IP地址。 Hot Potato寻路 热土豆算法会选择距离NEXT-HOP路由代价最小的路线。因而它是一个自私的算法，这个算法考虑的仅仅是希望在当前AS里面的代价最小。 Route-Selection Algorithm 在实际应用中，BGP应用的算法将会是如下这样，直到只剩下一条路径: 一个路线被赋予一个local优先级的值，就像AS-PATH和NEXT-HOP一样。这个local prefernece 可以被其他router设置，或者通过AS从其他的router获知。这个值如何确定则是完全取决于网络管理者如何决定的。那么具有最高local preference的值将会被选择。 当出现多个local preference时，那个拥有最短AS-PATH的将被选择, 一般而言BGP会使用DV算法， 如果仍然拥有相同的AS-PATH长度，则使用hot potato算法，如果仍然有剩余，则使用BGP表示符选择 5.4.4 IP-Anycast 除了用于AS间的路由协议，BGP还通常用于实现IP-anycast服务，这在DNS中十分常见。考虑以下场景(1)相同的内容在不同地理位置的服务器上(2)让每个用户可以访问到最近的服务器。 如上图所示，在IP Anycast阶段，CDN可以给服务器分配相同的IP地址，并使用标准的BGP协议从其他server获取IP地址。当BGP路由器收到多个相同IP的路径建议时，router会把它当做不同的路径。然后router使用BGP算法挑选最好的那个。 5.4.6 小结 获取网络服务的步骤:1.连接到当地地ISP，localISP会分配给一些地址如 a/24地址，包括256个地址，讲这些地址分配给Web服务器，邮件服务器等等.. 其次需要获取公司域名，并且需要在DNS里面有解析。并且提供自己DNS服务器的IP地址，最终会把DNS服务器(域名及IP地址)放到.com顶级服务器中。这步之后，任何用户知道你的域名就可以从DNS中获取ip地址了。 当一个不属于你的AS的人请求你的IP的一个包，router实际上一开始并不知道公司的prefix，这就要通过BGP来完成。 5.5 SDN 控制层 SDN架构有4个特性： 基于流的转发： 通过SDN控制的网关可以依据任何传输层，网络层，链路层的头部进行转发。而传统的方法，router只依据目的IP地址就行转发。转发的规则是由流控制表确定的，而这就是SDN控制层的任务：在所有网络的设备中确定，管理流控制部的entry。 分离数据部分和控制部分：数据部分由网络设备组成，相对而言比较简单但是很快速，并根据流控制表中的规则执行\"match plus action\"。而控制层则由服务器和软件来确定管理网关的表项。 网络控制功能位于数据层交换机的外部：如下图中所示，控制部分包含SDN控制器(网络操作系统)和一系列的网络控制的应用。controller维护网络状态的信息，提供给网络控制的应用程序，并且提供一些方法使得网络控制层的应用程序可以监测，运行，控制底层的网络设备。尽管图中的控制器是一个集中的服务器，实际上，一般都是通过多个服务器联合组合而成。 可编程的网络 通过网络控制的应用，网络是可以编程的。这些应用代表了SDN控制层的大脑。使用SDN控制器提供的API，应用就可以控制网络网络设备中的数据了。 5.5.2 SDN控制层：SDN控制器和SDN网络控制的应用 SDN控制器可以被分为如下三个层次： 通信层： SDN控制器和网络设备间的通信，一般而言需要一种协议来交互信息,如Openflow。 状态管理层：最终有关控制的决定由控制层决定，例如确定流控制表，实现负载均衡，防火墙等。所以这些信息需要被SDN控制器维护。 与控制网络的应用的接口 这通常是一组API，用来使得应用可以读写网络的状态和位于状态管理层的流表数据。如REST 需要注意的是，SDN控制器被认为是逻辑集中的，也就是说从外部看，这个控制器可以被看做是单一的服务。一般而言，这些服务和数据库(用来存储状态信息的)一般都是使用分布式的服务器来实现的，这是为了冗余纠错、高可靠性、性能等方面的考量。 5.5.3 OpenFlow 协议 OpenFlow协议是位于SDN控制器和一个SDN控制的交换机或者其他实现了OpenFlow API的设备。OpenFlow的操作通过TCP，默认端口号是6653. 从控制器到SDN控制的设备的重要信息如下： 配置： 这些信息允许控制器查询设置一个交换机的设置参数 改变状态： 这些信息使得控制器可以加入/删除/修改交换机流表的内容，并设置端口属性。 读取状态： 发包： 用来在特定的端口发送特定的包。 从SDN控制的设备到控制器的重要信息如下： Flow-Removed: 当出现time-out时某个流表被设备丢弃，这样为了使得控制器的信息同步，需要回传 端口状态：交换机告诉控制器关于端口状态的改变 输入的包： 当一个包到达交换机的输入端时，可能并不匹配任何流表的入口，这样这个包就需要发送给控制器进行额外处理。一些匹配的包可能也会发送给控制器，因为可能会有其他的动作需要进行。 5.5.4 数据和控制层交互的例子： 在这个图中的情景和早期的每个router都有一个控制器时完全不同的： Dijkstra算法时执行在交换机之外，可以看作是一个分离的程序 交换机更新链路至SDN控制器，而不是给其他的交换机 在这个例子中，假定s1-s2的链路断开了，s1,s3,s4的最短链路被影响，而s2没有影响(?),并假定Openflow时用作于通信层的协议，控制层只有链路状态算法寻路的功能。那么过程如下： s1知道s1->s2这个链路现在走不通了，于是通过openflow的端口状态信息告知控制器。 SDN控制器收到1中的信息，并告知链路状态管理器，后者更新链路状态数据库。 网络层控制的应用(实现了Dijkstra的算法那个)收到了这个状态改变的信息。 该应用和链路状态管理器进行交互并更新链路状态，并可能和其他的组件交互，最终生成新的最小代价路径。 应用和流表管理器交互。 流表管理器使用openflow协议更新流表入口。 5.6 ICMP(Internet Control Message Protocol) ICMP是host和router交互网络层信息的途径。最经典的ICMP使用是错误报告。例如当运行一个HTTP会话时，可能会包含一个错误的信息如目标网络地址不可到达。 ICMP通常被认为是IP的一部分，但是从结构上讲，它位于IP的上方，因为ICMP的消息是位于IP数据报内部的。也就是ICMP信息以IP payload的形式携带传输。就像TCP和UDP的段以IP payload的形式传输一样。 ICMP信息有type和code位，并且包含头部和IP数据报的前8个字节。最著名的ping陈谷，发送ICMP type8 code0 信息to特定的host。然后目标host响应这个echo，发送type0 code0的ICMP信息。 另一个关于ICMP信息的有趣之处是source quench(熄灭) message. 在实际中这个内容虽然很少使用。它原本的目的是进行拥堵控制，它允许一个路由器给一个host发送一个ICMP报文使得其减少传输速率。 Traceroute也是依靠ICMP实现的 const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'computer-network-top2down', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitalk.render('gitalk-container') require(['gitbook'], function(gitbook) { const gitalk = new Gitalk({ clientID: '8c56e9dae52cf0da1582', clientSecret: '5dc33ee4d70a65898c90f64836a44e63d25ff747', repo: 'cyc10-rcore-tutorial', owner: 'moon548834', admin: ['moon548834'], createIssueManually: true, id: document.title }) gitbook.events.bind('page.change', initMygitalk) function initMygitalk() { gitalk.render('gitalk-container') } }) "}}